# -*- coding: utf-8 -*-
"""001.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mfRcSBw_8GSb4VOM969kvTd91oy-bZjc

# ****Akaike Structured Data Assignement****

# **Problem**

The development of drugs is critical in providing therapeutic options
for patients suffering from chronic and terminal illnesses. “Target Drug”, in particular,
is designed to enhance the patient's health and well-being without causing
dependence on other medications that could potentially lead to severe and
life-threatening side effects. These drugs are specifically tailored to treat a particular
disease or condition, offering a more focused and effective approach to treatment,
while minimising the risk of harmful reactions.

The objective in this assignment is to develop a predictive model which will predict
whether a patient will be eligible*** for “Target Drug” or not in next 30 days. Knowing
if the patient is eligible or not will help physician treating the patient make informed
decision on the which treatments to give.

### **Importing Libraries**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import f1_score, roc_curve, auc, accuracy_score
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier

"""To ignore warnings"""

import warnings
warnings.filterwarnings("ignore")

"""### **Loading Dataset**

Train Data
"""

train_df=pd.read_parquet("/content/sample_data/train.parquet")

"""### **Analysis of Data**

Checking size of dataset
"""

print("Data set size : ", train_df.shape)

"""From the above result no of rows are 3220868 and no of columns are 3

Fetching top 5 row in dataset
"""

train_df.head()

"""Fetching Bottom 5 rows"""

train_df.tail()

"""Finding the column names"""

train_df.columns

"""Basic statistical analysis of dataset"""

train_df.describe()

"""## **Data Preprocessing**

checking for null values
"""

train_df.isnull().sum()

"""From the above result we can clearly understand there is no missing value.

checking for no of duplicate values
"""

train_df.duplicated().sum()

"""from the above result we can clearly understand 35571 values are duplicate. there is no use of duplicate values so we will delete all duplicate values.

droping duplicates
"""

train_df = train_df.drop_duplicates()

"""after droping again check for no of duplicates"""

train_df.duplicated().sum()

"""duplicates are removed from the data set.

Checking Data Type
"""

train_df.dtypes

"""Unique Values of Incident Column"""

print("Unique values of Incident \n")
print(train_df['Incident'].unique())

"""From all the above result all values are unique which means there is no incorrect or wrong data that is spelling mistake, upper case and lower case mismatch of each values.

No of counts for particular Incident
"""

train_df.Incident.value_counts()

"""No of counts for particular Date"""

train_df.Date.value_counts()

"""Generating positive set"""

positive_df = train_df[train_df['Incident']=='TARGET DRUG']
positive_df.head()

"""Shape of positive set"""

positive_df.shape

"""Generating negative set"""

negative =  train_df[~train_df['Patient-Uid'].isin(positive_df['Patient-Uid'])]
negative_df = negative.groupby('Patient-Uid').tail(1)
negative_df

"""Shape of negative set"""

negative_df.shape

"""To get the count of previous prescriptions within specific time intervals"""

positive_df['Prescription_Count'] = positive_df.groupby('Patient-Uid')['Date'].cumcount()
negative_df['Prescription_Count'] = negative_df.groupby('Patient-Uid')['Date'].cumcount()
positive_df.tail(5)

negative_df.tail()

"""To get the difference between the most recent prescription and the prediction date."""

prediction_date = pd.to_datetime('today') + pd.DateOffset(days=30)
positive_df['Time_diff'] = (prediction_date - positive_df.groupby('Patient-Uid')['Date'].transform('max')).dt.days
negative_df['Time_diff'] = (prediction_date - negative_df.groupby('Patient-Uid')['Date'].transform('max')).dt.days

positive_df.head()

negative_df.head()

"""To create a new dataset in concatenation of positive set and negative set"""

new_df = pd.concat([positive_df, negative_df])
new_df.head()

new_df.shape

"""Splitting dataset into train & test sets"""

X_train,X_test,y_train,y_test = X_train, X_test, y_train, y_test = train_test_split(new_df[['Prescription_Count', 'Time_diff']], new_df['Incident'] == 'TARGET DRUG', test_size = 0.25, random_state=42)

X_train.shape,X_test.shape,y_train.shape,y_test.shape

"""Building model to train the data"""

xgb_classifier =  XGBClassifier(random_state=42)
xgb_classifier.fit(X_train, y_train)

"""Predicting test data"""

y_pred = xgb_classifier.predict(X_test)

"""To evaluate the model - confusion_matrix"""

confusion_matrix_report = confusion_matrix(y_test, y_pred)
confusion_matrix_report

"""Evaluating the model - classification report"""

print(classification_report(y_test, y_pred))

"""Calculating F1 score"""

F1_score = f1_score(y_test, y_pred)
F1_score

"""Model accuracy"""

accuracy_score(y_test, y_pred)

"""Evaluating model by roc_auc curve"""

fpr,tpr, thresold = roc_curve(y_test, y_pred)
roc_auc = auc(fpr,tpr)
plt.plot(fpr,tpr, label = 'AUC = %0.3f' % roc_auc)
plt.plot([0,1],[0,1],'--')
plt.title('ROC_AUC curve')
plt.legend(loc='lower right')
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.show()

"""### **Loading Dataset**

Test Data
"""

test_df = pd.read_parquet("/content/sample_data/test.parquet")

"""## **Analysis of Data**

Checking size of dataset
"""

print("Data set size : ", test_df.shape)

"""From the above result no of rows are 1065524 and no of columns are 3

Fetching top 5 row in dataset
"""

test_df.head()

"""Fetching Bottom 5 rows"""

test_df.tail()

"""Finding the column names"""

test_df.columns

"""Basic statistical analysis of dataset"""

test_df.describe()

"""### **Data Preprocessing**

Checking for null values
"""

test_df.isnull().sum()

"""checking for no of duplicate values"""

test_df.duplicated().sum()

"""From the above result we can find 12100 duplicate datas. So will drop the duplicates.

Droping duplicates
"""

test_df = test_df.drop_duplicates()

"""After droping agin check for no of duplicates"""

test_df.duplicated().sum()

"""Duplicates are removed from dataset.

Checking Data Type
"""

test_df.dtypes

"""Unique Values of Incident"""

print("Unique values of Incident \n")
print(test_df['Incident'].unique())

"""No of counts for particular Incident"""

test_df.Incident.value_counts()

"""Generating positive set"""

positive_df = test_df[test_df['Incident']=='TARGET DRUG']
positive_df.head()

"""Shape of positive set"""

positive_df.shape

"""Negative Dataset"""

negative =  test_df[~test_df['Patient-Uid'].isin(positive_df['Patient-Uid'])]
negative_df = negative.groupby('Patient-Uid').tail(1)
negative_df

"""Shape of negative set"""

negative_df.shape

positive_df['Prescription_Count'] = positive_df.groupby('Patient-Uid')['Date'].cumcount()
negative_df['Prescription_Count'] = negative_df.groupby('Patient-Uid')['Date'].cumcount()
positive_df.tail(5)

"""To get the count of previous prescriptions within specific time intervals"""

negative_df.tail()

prediction_date = pd.to_datetime('today') + pd.DateOffset(days=30)
positive_df['Time_diff'] = (prediction_date - positive_df.groupby('Patient-Uid')['Date'].transform('max')).dt.days
negative_df['Time_diff'] = (prediction_date - negative_df.groupby('Patient-Uid')['Date'].transform('max')).dt.days

"""To get the difference between the most recent prescription and the prediction date."""

positive_df.head()

negative_df.head()

new_df = pd.concat([positive_df, negative_df])
new_df.head()

"""To create a new dataset in concatenation of positive set and negative set"""

new_df.shape

train_df.drop_duplicates(inplace = True)

test_df['Prescription_Count'] = test_df.groupby('Patient-Uid')['Date'].cumcount()
test_df['Time_Difference'] = (prediction_date - test_df.groupby('Patient-Uid')['Date'].transform(max)).dt.days

test_data_pred = xgb_classifier.predict(test_df[['Prescription_Count', 'Time_Difference']])

"""To create final submission file"""

Final_submission = pd.DataFrame({'Patient-Uid': test_df['Patient-Uid'], 'Prediction': test_data_pred})
Final_submission.head()

Final_submission.to_csv('Final_submission.csv', index = False)